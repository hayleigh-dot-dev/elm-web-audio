[{"name":"WebAudio","comment":"\n# Types\n@docs Node, Type, Key, Graph\n\n# Basic Constructors\n@docs node, ref, key, param\n\n# Web Audio Nodes\n## Common audio nodes\n@docs oscillator, osc, gain, audioDestination, dac, audioBufferSource, delay\n\n## Utility nodes\n@docs channelMerger, channelSplitter, constantSource\n\n## Signal processing nodes\n@docs biquadFilter, convolver, dynamicsCompressor, iirFilter, panner, stereoPanner, waveShaper\n\n# JSON Encoding\nTo turn the json in Web Audio nodes, you need to know what that data looks like.\nHere's a breakdown of how everything is encoded:\n\n**Node:**\n\n```json\n{\n    \"type\": \"OscillatorNode\",\n    \"properties\": [\n        ...\n    ],\n    \"connections\": [\n        ...\n    ]\n}\n```\n\n**Keyed:**\n\n```json\n{\n    \"key\": \"myOsc\",\n    \"type\": \"OscillatorNode\",\n    \"properties\": [\n        ...\n    ],\n    \"connections\": [\n        ...\n    ]\n}\n```\n\n**Ref:**\n\n```json\n{\n    \"key\": \"myOsc\",\n    \"type\": \"RefNode\"\n}\n```\n\nProperties can come in two types, AudioParam and NodeProperty. While the Web \nAudio API doesn't make an official distinction between the two, how they are \nused differs.\n\nAudioParams represent parameters that can be updated at either audio rate \n(a-rate) or control rate (k-rate). Other audio nodes can connect to an \nAudioParam and modulate its value in real time. Examples of AudioParams include \nfrequency, gain, and delayTime.\n\n**AudioParam:**\n\n```json\n{\n    \"type\": \"AudioParam\",\n    \"label\": \"frequency\",\n    \"value\": 440\n}\n```\n\nNodeProperties are any other parameter on an audio node. An example of a \nNodeProperty is an OscillatorNode's \"type\" parameter.\n\n**NodeProperty:**\n\n```json\n{\n   \"type\": \"NodeProperty\",\n   \"label\": \"type\",\n   \"value\": \"square\"\n}\n```\n\n@docs encode, encodeGraph\n\n","unions":[{"name":"Node","comment":" The core building block of any Web Audio signal graph. `Keyed` nodes are \njust like regular nodes but with an additonal `Key` property. This allows `Ref` \nnodes to reference them elsewhere in the graph!\n","args":[],"cases":[]}],"aliases":[{"name":"Graph","comment":" ","args":[],"type":"List.List WebAudio.Node"},{"name":"Key","comment":" A simple type alias representing unique key used to identify nodes. Use \n`Key`s like you would use the `id` attribute on a HTML element.\n","args":[],"type":"String.String"},{"name":"Type","comment":" A simple type alias representing the type of `Node`. This could be \nsomething like \"OscillatorNode\" or \"RefNode\".\n","args":[],"type":"String.String"}],"values":[{"name":"audioBufferSource","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode>\nCommon properties:\n\n  - buffer\n  - detune\n  - loop\n  - loopStart\n  - loopEnd\n  - playbackRate\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"audioDestination","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/AudioDestinationNode>\n","type":"WebAudio.Node"},{"name":"biquadFilter","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/BiquadFilterNode>\nCommon properties:\n\n  - frequency\n  - detune\n  - Q\n  - type\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"channelMerger","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/ChannelMergerNode>\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"channelSplitter","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/ChanneSplliterNode>\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"constantSource","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/ConstantSourceNode>\nCommon properties:\n\n  - offset\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"convolver","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/ConvolverNode>\nCommon properties:\n\n  - buffer\n  - normalize | normalise\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"dac","comment":" An alias for `audioDestination`.\n","type":"WebAudio.Node"},{"name":"delay","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/DelayNode>\nCommon properties:\n\n  - delayTime\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"dynamicsCompressor","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/DynamicsCompressorNode>\nCommon properties:\n\n  - threshold\n  - knee\n  - ratio\n  - reduction\n  - attack\n  - release\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"encode","comment":" Converts a `Node` into a Json value. Use this to send a node through a port \nto javascipt, where it can be constructed into a Web Audio node!\n","type":"WebAudio.Node -> Json.Encode.Value"},{"name":"encodeGraph","comment":" Encode a graph of nodes into a Json value. More than likely you'll use this \nmore than `encode`\n","type":"WebAudio.Graph -> Json.Encode.Value"},{"name":"gain","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/GainNode>\nCommon properties:\n\n  - gain\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"iirFilter","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/>\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"key","comment":" Use this function to apply a key to a node. In the case of already keyed \nnodes, or ref nodes, this will update the key to the new value.\n\n    a = osc [ Property.freq 440 ] [ dac ]\n    b = keyedGain \"b\" [ Property.gain 0.5 ] [ dac ]\n    c = ref \"b\"\n\n    key a \"myOsc\" -- Give a the key \"myOsc\"\n    key b \"myGain\" -- Rename b's key to \"myGain\"\n    key c \"myOsc\" -- c is now a RefNode to \"myOsc\"\n\n","type":"WebAudio.Key -> WebAudio.Node -> WebAudio.Node"},{"name":"node","comment":" General way to construct Web Audio nodes. This is used to create all the \nhelper functions below. You can use this function to define custom nodes by \npartially applying just the `type` parameter. This is handy if you're using a \nlibrary like Tone.js and want to use those nodes in Elm.\n\n    omniOscillator : List Property -> List Node -> Node\n    omniOscillator =\n        node \"Tone-OmniOscillatorNode\"\n\n    myOsc =\n        omniOscillator\n            [ Property.freq 440 ]\n            [ dac ]\n\n","type":"WebAudio.Type -> List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"osc","comment":" An alias for `oscillator`.\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"oscillator","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode>\nCommon properties:\n\n  - frequency\n  - detune\n  - type\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"panner","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/PannerNode>\nCommon properties:\n\n  - coneInnerAngle\n  - coneOuterAngle\n  - coneOuterGain\n  - distanceModel\n  - maxDistance\n  - orientationX\n  - orientationY\n  - orientationZ\n  - panningModel\n  - positionX\n  - positionY\n  - positionZ\n  - refDistance\n  - rolloffFactor\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"param","comment":" Audio nodes can connect to AudioParams to modulate their value. Use this\nfunction for that. The first argument is the key of an existing keyedd node and\nthe second argument is the name of the AudioParam to connect to.\n\nThis is commonly used for frequency modulation (FM) and amplitude modulation\n(AM) synthesis.\n\n    a = osc [ frequency 10 ] [ param \"carrier\" \"frequency\" ]\n    b = key \"carrier\" <| osc [] [ dac ]\n\nUnder the hood, this actually just creates a standard ref node! You could create\nthis function yourself:\n\n    param key name = ref (key ++ \".\" name)\n    \n","type":"WebAudio.Key -> String.String -> WebAudio.Node"},{"name":"ref","comment":" A ref node is used to refer to a keyed node elsewhere in the graph. This is \nhow we connect multiple \"chains\" of nodes together and represet a graph in a \nsimple list.\n","type":"WebAudio.Key -> WebAudio.Node"},{"name":"stereoPanner","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/StereoPannerNode>\nCommon properties:\n\n  - pan\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"},{"name":"waveShaper","comment":" See: <https://developer.mozilla.org/en-US/docs/Web/API/WaveShaperNode>\nCommon properties:\n\n  - curve\n  - oversample\n\n","type":"List.List WebAudio.Property.Property -> List.List WebAudio.Node -> WebAudio.Node"}],"binops":[]},{"name":"WebAudio.Property","comment":"\n\n# Types\n@docs Property, Value\n\n# Basic Constructors\n@docs nodeProperty, audioParam\n\n## Primatives\n@docs bool, float, floatList, int, string\n\n## Scheduled Audio Params\n@docs setValueAtTime, linearRampToValueAtTime, exponentialRampToValueAtTime\n\n# Properties\n@docs attack, buffer, coneInnerAngle, coneOuterAngle, coneOuterGain, curve, delayTime, detune, distanceModel, fftSize, frequency, gain, knee, loop, loopEnd, loopStart, maxChannelCount, maxDecibels, minDecibels, normalize, offset, orientationX, orientationY, orientationZ, oversample, pan, panningModel, playbackRate, positionX, positionY, positionZ, q, ratio, reduction, refDistance, release, rolloffFactor, smoothingTimeConstant, threshold, type_\n\n# JSON Encoding\n@docs encode\n\n","unions":[{"name":"Property","comment":" A type to encapsulate all the different properties that can exist on a Web\nAudio node. This could be something like an oscillator's frequency, whether an\naudio buffer is set to loop, or whether a filter is a highpass or a lowpass\nfilter.\n\n\nThe implementation is currently concealled because I don't *think* it is necessary \nto distinguish between the different types of Property when developing.\n","args":[],"cases":[]},{"name":"Value","comment":" Properties can have different types of value, for example the frequency \nproperty of an oscillator is a `Float` but its type property is a `String`. To\ncapture all these posibilities we have a special Value type.\n\nSee the Primatives section below for functions create Values yourself. This is\nonly necessary if you're creating a Property manually because you're using some\ncustom audio nodes or you can't find a Property below.\n\n> *Note: If you can't find a Property but it's exists on a standard Web Audio node,\nconsider submitting an issue or a pull request to add it!*\n","args":[],"cases":[]}],"aliases":[],"values":[{"name":"attack","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"audioParam","comment":" \n\n> *Node: It is rare to need to create your own properties in this way.*\n","type":"String.String -> WebAudio.Property.Value -> WebAudio.Property.Property"},{"name":"bool","comment":" Convert a `Bool` to a Property value.\n\n    import WebAudio.Property exposing (nodeProperty, bool)\n\n    nodeProperty \"loop\" (bool True)\n","type":"Basics.Bool -> WebAudio.Property.Value"},{"name":"buffer","comment":" ","type":"List.List Basics.Float -> WebAudio.Property.Property"},{"name":"coneInnerAngle","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"coneOuterAngle","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"coneOuterGain","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"curve","comment":" ","type":"List.List Basics.Float -> WebAudio.Property.Property"},{"name":"delayTime","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"detune","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"distanceModel","comment":" ","type":"String.String -> WebAudio.Property.Property"},{"name":"encode","comment":" ","type":"WebAudio.Property.Property -> Json.Encode.Value"},{"name":"exponentialRampToValueAtTime","comment":" Schedule an exponential ramp of a property value from now untl some point in the\nfuture. Try to make sure the value is non-zero!\n\n    import WebAudio.Property exposing (exponentialRampToValueAtTime, frequency)\n\n    exponentialRampToValueAtTime (frequency 440) 1\n\nIt's important to note that `1` refers to one second after an Audio Context has\nstarted, **not** one second from *now*. This is best used once you have the\n[current time](/WebAudio.Context#currentTime) from an existing Audio Context.\n","type":"WebAudio.Property.Property -> Basics.Float -> WebAudio.Property.Property"},{"name":"fftSize","comment":" ","type":"Basics.Int -> WebAudio.Property.Property"},{"name":"float","comment":" Convert a `Float` to a Property value.\n\n    import WebAudio.Property exposing (audioParam, float)\n\n    audioParam \"detune\" (float 0.2)\n","type":"Basics.Float -> WebAudio.Property.Value"},{"name":"floatList","comment":" Convert a list of `Float`s to a Property value.\n\n    import WebAudio.Property exposing (nodeProperty, floatList)\n\n    nodeProperty \"buffer\" (floatList [0, 0.5, 1, 0.5, 0, -0.5, -1])\n","type":"List.List Basics.Float -> WebAudio.Property.Value"},{"name":"frequency","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"gain","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"int","comment":" Convert an `Int` to a Property value.\n\n    import WebAudio.Property exposing (nodeProperty, int)\n\n    nodeProperty \"fftSize\" (int 512)\n","type":"Basics.Int -> WebAudio.Property.Value"},{"name":"knee","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"linearRampToValueAtTime","comment":" Schedule a linear ramp of a property value from now untl some point in the\nfuture.\n\n    import WebAudio.Property exposing (linearRampToValueAtTime, frequency)\n\n    linearRampToValueAtTime (frequency 440) 1\n\nIt's important to note that `1` refers to one second after an Audio Context has\nstarted, **not** one second from *now*. This is best used once you have the\n[current time](/WebAudio.Context#currentTime) from an existing Audio Context.\n","type":"WebAudio.Property.Property -> Basics.Float -> WebAudio.Property.Property"},{"name":"loop","comment":" ","type":"Basics.Bool -> WebAudio.Property.Property"},{"name":"loopEnd","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"loopStart","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"maxChannelCount","comment":" ","type":"Basics.Int -> WebAudio.Property.Property"},{"name":"maxDecibels","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"minDecibels","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"nodeProperty","comment":" \n\n> *Note: It is rare to need to create your own properties in this way.*\n","type":"String.String -> WebAudio.Property.Value -> WebAudio.Property.Property"},{"name":"normalize","comment":" ","type":"Basics.Bool -> WebAudio.Property.Property"},{"name":"offset","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"orientationX","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"orientationY","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"orientationZ","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"oversample","comment":" ","type":"String.String -> WebAudio.Property.Property"},{"name":"pan","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"panningModel","comment":" ","type":"String.String -> WebAudio.Property.Property"},{"name":"playbackRate","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"positionX","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"positionY","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"positionZ","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"q","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"ratio","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"reduction","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"refDistance","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"release","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"rolloffFactor","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"setValueAtTime","comment":" Schedule an update to a property to take place at some point in the future.\n\n    import WebAudio.Property exposing (setValueAtTime, frequency)\n\n    setValueAtTime (frequency 440) 1\n\nIt's important to note that `1` refers to one second after an Audio Context has\nstarted, **not** one second from *now*. This is best used once you have the\n[current time](/WebAudio.Context#currentTime) from an existing Audio Context.\n","type":"WebAudio.Property.Property -> Basics.Float -> WebAudio.Property.Property"},{"name":"smoothingTimeConstant","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"string","comment":" Convert a `String` to a Property value.\n\n    import WebAudio.Property exposing (nodeProperty, string)\n\n    nodeProperty \"type\" (string \"triangle\")\n","type":"String.String -> WebAudio.Property.Value"},{"name":"threshold","comment":" ","type":"Basics.Float -> WebAudio.Property.Property"},{"name":"type_","comment":" ","type":"String.String -> WebAudio.Property.Property"}],"binops":[]}]