# Elm-Web-Audio

> *An elm/html-like library for the Web Audio API*.

## About
This library aims to provide a simple way of creating Web Audio processing graphs 
in Elm. It was motivated by the desire to keep as much of my audio code as possible
inside Elm before resorting to ports.

To that end I present an elm/html-like library for constructing *virtual* audio
graphs that can be sent through a port to be constructed in javascript. This means
entire audio processing graphs can be described in a powerful, declarative fashion
just like the DOM is:

```
-- elm/html
div : List Attribute -> List (Html a) -> Html a

-- elm-web-audio
osc : List Property -> List Node -> Node
```

This means we can naturally represent chains of audio nodes, and easily visualise
their connections:

```
audio : Model -> Graph
audio model =
  [ oscillator [ frequency model.freq ]
    [ audioDestination ]
  ]
```

Notice how we're using our application's Model to set the frequency of the oscillator.
If we hook our application up right, we get all the benefits of The Elm Architecture
for our audio graph just as we do for our view!

Checkout the example to see how everything gets hooked up.

## Getting Started
To actually make some sounds, you'll need some javascript to take the virtual
audio graph generated by Elm and turn it into real audio nodes. There is a
reference implementation found in [example/virtual-audio.js](https://github.com/pd-andy/elm-web-audio/blob/master/example/virtual-audio.js)
that you can copy into your own projects (in the future it would be nice if this
were its own library).

```javascript
import { Elm } from './Main.elm'
import VirtualAudioGraph from './virtual-audio'

const context = new AudioContext()
const audio = new VirtualAudioGraph(context)

// Chrome autplay policy demans some user interaction
// takes place before the AudioContext can be resumed.
window.addEventListener('click', () => {
  if (context.state === 'suspended') context.resume()
})

const App = Elm.Main.init({
  node: document.querySelector('#app'),
  flags: { context }
})

App.ports.updateAudio.subscribe(graph => {
  audio.update(graph)
})
```

Above is all the javascript needed to get going. Remember to pass the audio 
context in as part of your `flags` if you want to make use of the WebAudio.Context
module.

On the Elm side, you just need to declare a single port `updateAudio`:

```elm
port updateAudio : Json.Encode.Value -> Cmd msg
```

and a function that generates an audio graph from your model and sends it down
the port. In the example project it looks like this:

```elm
audio : Model -> Cmd Msg
audio model =
  List.map voice model.notes
    |> WebAudio.encodeGraph
    |> updateAudio
```

And that's it. Now whenever we want to generate a new graph, we can call the
`audio` function with the current model and return the `Cmd Msg` as part of the
`update` function!
